{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch Tutoral 1.ipynb","provenance":[],"authorship_tag":"ABX9TyPYTKJgkcXnTCrPcLOHsJig"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BwW4LjdMtm6Q"},"source":["## What is PyTorch?\n","it's python based scientific computing package targeted as two oset of audiences:\n","\n","\n","*   A replacement of NumPy to use the power GPUs\n","*   A deep learning researc platform that provides maximum flexibility and speed\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"y4Bbw_gPuH1q"},"source":["### Tensor\n","\n","Tensor are similar to NUmPy's ndarrays, with addition being that Tensors can also be used on A GPU to accelerate computing"]},{"cell_type":"code","metadata":{"id":"3JmwJabUtfrs","executionInfo":{"status":"ok","timestamp":1604205333685,"user_tz":-420,"elapsed":4589,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}}},"source":["from __future__ import print_function\n","import torch"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OGccoRwTur73"},"source":["construct a 5x3 matrix, uninitialized."]},{"cell_type":"code","metadata":{"id":"AVTrM_BRucPX","executionInfo":{"status":"ok","timestamp":1604205333686,"user_tz":-420,"elapsed":4582,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"b60ba004-3b29-4baf-82e9-b72830d762f6","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = torch.empty(5, 3)\n","x"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.7604e-37, 0.0000e+00, 3.3631e-44],\n","        [0.0000e+00,        nan, 0.0000e+00],\n","        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n","        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n","        [9.2198e-39, 7.0374e+22, 2.6133e-36]])"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"PUyZj9FSu9lS"},"source":["construct a randomly initialized matrix:"]},{"cell_type":"code","metadata":{"id":"z3rjVSW2u2bd","executionInfo":{"status":"ok","timestamp":1604205333688,"user_tz":-420,"elapsed":4577,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"727616f7-6f11-4db6-96a8-31b8f759cd19","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = torch.rand(5, 3)\n","x"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3695, 0.1000, 0.5117],\n","        [0.9728, 0.6000, 0.9488],\n","        [0.8275, 0.6408, 0.5906],\n","        [0.7063, 0.1848, 0.5980],\n","        [0.4188, 0.2305, 0.3213]])"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"d2bRk74uvK5k"},"source":["construct a matrix fulled zeros and dtype long"]},{"cell_type":"code","metadata":{"id":"XzR_TtSovWhN","executionInfo":{"status":"ok","timestamp":1604205333690,"user_tz":-420,"elapsed":4572,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"2a11ac91-a17c-4e50-edee-1ae44e276ab6","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = torch.zeros(5, 3)\n","x"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"dD3YPZJbvEvt","executionInfo":{"status":"ok","timestamp":1604205333691,"user_tz":-420,"elapsed":4564,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"5502a55c-fc99-44ef-d31a-dee473dcc783","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = torch.zeros(5, 3, dtype = torch.long)\n","x"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"Ppw0SYdbvxKA"},"source":["construct tensor directly from data"]},{"cell_type":"code","metadata":{"id":"BhxGBj1Xvlag","executionInfo":{"status":"ok","timestamp":1604205333693,"user_tz":-420,"elapsed":4558,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"a7fbe303-5957-4835-93cb-fadd4f450fd1","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = torch.tensor([5.5, 3])\n","x"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([5.5000, 3.0000])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"L7ZgeZ2Av7SP","executionInfo":{"status":"ok","timestamp":1604205333695,"user_tz":-420,"elapsed":4552,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"07bf4a9e-e358-4d45-b9e8-d74bbba03f3c","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = x.new_ones(5, 3, dtype = torch.double)  # new_ + method taka in size\n","print(x)\n","\n","x = torch.randn_like(x, dtype = torch.float)  # override dtype:\n","print(x)                                      # result has rhe same size"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]], dtype=torch.float64)\n","tensor([[ 1.0179,  1.2472,  1.1268],\n","        [-0.3973, -1.1798,  0.4555],\n","        [-0.0844,  0.8238, -0.6912],\n","        [ 0.7279,  0.3065,  0.2901],\n","        [ 1.6041, -2.0209, -0.2634]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WlMfWoUkwVG7","executionInfo":{"status":"ok","timestamp":1604205333696,"user_tz":-420,"elapsed":4546,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"dca0c6fb-4e5d-44c5-bb3e-ae8fd35e0529","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Get its size\n","x.size()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 3])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"cLS4ixxNyEKT"},"source":["Note:\n","\n","\n","> torch.Size is in fact a tuple, so it supports all tuple operations.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MFI16pOyySFi"},"source":["### Operations\n","there are multiple syntaxes for the operations. In the following example, we will take a look at the addition operation."]},{"cell_type":"markdown","metadata":{"id":"eIUQzIBcyjU2"},"source":["addition syntax 1"]},{"cell_type":"code","metadata":{"id":"WPJIDfNjyA-z","executionInfo":{"status":"ok","timestamp":1604205333697,"user_tz":-420,"elapsed":4540,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"8ae780ff-db98-4505-ec85-2be1754d9e6d","colab":{"base_uri":"https://localhost:8080/"}},"source":["y = torch.rand(5, 3)\n","x + y"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.8342,  1.8122,  1.2623],\n","        [ 0.0466, -0.5550,  1.3462],\n","        [ 0.1267,  1.3586, -0.1761],\n","        [ 1.4779,  1.1529,  0.5853],\n","        [ 1.6335, -1.8801, -0.1944]])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"r-S7b4oMyyJN"},"source":["addition syntax 2"]},{"cell_type":"code","metadata":{"id":"-m0KNKvqyr4q","executionInfo":{"status":"ok","timestamp":1604205333698,"user_tz":-420,"elapsed":4532,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"a30ef00f-e229-48f9-eca8-c121a5012c53","colab":{"base_uri":"https://localhost:8080/"}},"source":["torch.add(x, y)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.8342,  1.8122,  1.2623],\n","        [ 0.0466, -0.5550,  1.3462],\n","        [ 0.1267,  1.3586, -0.1761],\n","        [ 1.4779,  1.1529,  0.5853],\n","        [ 1.6335, -1.8801, -0.1944]])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"iX6rKrv5y6zU"},"source":["addition 3, providing an output tensor as argument"]},{"cell_type":"code","metadata":{"id":"8gdtT4syy2uZ","executionInfo":{"status":"ok","timestamp":1604205333700,"user_tz":-420,"elapsed":4527,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"e7c87335-1c0a-4a2b-ea74-0b40e5625454","colab":{"base_uri":"https://localhost:8080/"}},"source":["result = torch.empty(5, 3)\n","torch.add(x, y, out = result)\n","result"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.8342,  1.8122,  1.2623],\n","        [ 0.0466, -0.5550,  1.3462],\n","        [ 0.1267,  1.3586, -0.1761],\n","        [ 1.4779,  1.1529,  0.5853],\n","        [ 1.6335, -1.8801, -0.1944]])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"YAv3DOIezMRr"},"source":["additionn 4, in-place"]},{"cell_type":"code","metadata":{"id":"zApfQUyWzICe","executionInfo":{"status":"ok","timestamp":1604205333701,"user_tz":-420,"elapsed":4520,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"39f6af68-fe40-4139-9e29-79a5582e2b8b","colab":{"base_uri":"https://localhost:8080/"}},"source":["y.add_(x)   # this will chane the original value of y"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.8342,  1.8122,  1.2623],\n","        [ 0.0466, -0.5550,  1.3462],\n","        [ 0.1267,  1.3586, -0.1761],\n","        [ 1.4779,  1.1529,  0.5853],\n","        [ 1.6335, -1.8801, -0.1944]])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"QpZctOPK0E_y"},"source":["we can use standard NumPy-like indexing with all bells and whistles!"]},{"cell_type":"code","metadata":{"id":"V8XLIztlzZar","executionInfo":{"status":"ok","timestamp":1604205333702,"user_tz":-420,"elapsed":4514,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"77e07152-b84d-4b71-a089-7634289b89dd","colab":{"base_uri":"https://localhost:8080/"}},"source":["x[:, 1]"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 1.2472, -1.1798,  0.8238,  0.3065, -2.0209])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"aBeXiCyq0Z_A"},"source":["we can resize/reshape our tensor with ***torch.view***"]},{"cell_type":"code","metadata":{"id":"fSvsbQ2Sz9Vu","executionInfo":{"status":"ok","timestamp":1604205333703,"user_tz":-420,"elapsed":4509,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"71d2438a-6471-4430-9bc2-16598f2aa5cc","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = torch.rand(4, 4)\n","print(x.size())\n","y = x.view(16)\n","print(y.size())\n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n","print(z.size())"],"execution_count":14,"outputs":[{"output_type":"stream","text":["torch.Size([4, 4])\n","torch.Size([16])\n","torch.Size([2, 8])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BPZBDJkr1GRK"},"source":["tp get value from one element tensor, use ***.item()***  to get value as a Python number"]},{"cell_type":"code","metadata":{"id":"XHBHqy3m04ZR","executionInfo":{"status":"ok","timestamp":1604205333704,"user_tz":-420,"elapsed":4504,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"f8258406-f584-458e-9f10-628a70b9211d","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = torch.randn(1)\n","print(x)\n","print(x.item())"],"execution_count":15,"outputs":[{"output_type":"stream","text":["tensor([0.1247])\n","0.12473121285438538\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zwzs1BYG2h7p"},"source":["**Read later:**\n","\n","\n","  100+ Tensor operations, including transposing, indexing, slicing,\n","  mathematical operations, linear algebra, random numbers, etc.,\n","  are described\n","  `here <https://pytorch.org/docs/torch>`_."]},{"cell_type":"markdown","metadata":{"id":"3KNRxr-b3GQs"},"source":["### NumPy Bridge\n","\n","Converting a Torch to a Numpy array and a NumPy to Tensor.\n","\n","    The Torch Tensor and NumPy array will share their underlying memory locations (if the Torch Tensor is on CPU), and changing one will change the other."]},{"cell_type":"markdown","metadata":{"id":"uifHIQPm3T2A"},"source":["Converting a Torch Tensor to a NumPy Array"]},{"cell_type":"code","metadata":{"id":"fwJky07H2-e1","executionInfo":{"status":"ok","timestamp":1604205333705,"user_tz":-420,"elapsed":4498,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"70fbb35c-1c43-4f53-ea53-9384a578c558","colab":{"base_uri":"https://localhost:8080/"}},"source":["a = torch.ones(5)\n","a"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 1., 1., 1., 1.])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"hylfAX8D3Vps","executionInfo":{"status":"ok","timestamp":1604205333705,"user_tz":-420,"elapsed":4492,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"d57b084c-d643-4c5f-eb21-e700aa3d5218","colab":{"base_uri":"https://localhost:8080/"}},"source":["b = a.numpy()\n","b"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1., 1., 1.], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"DGjTMHcz3q4Z"},"source":["See how the numpy array changed in value."]},{"cell_type":"code","metadata":{"id":"IJqMfc183kJG","executionInfo":{"status":"ok","timestamp":1604205333706,"user_tz":-420,"elapsed":4486,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"6c8f2188-9596-4d49-e821-2d1056fe3d7f","colab":{"base_uri":"https://localhost:8080/"}},"source":["a.add_(1)\n","print(a)\n","print(b)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zTo-FY5pEYOY"},"source":["Converting a Numpy Array to Torch Tensor"]},{"cell_type":"code","metadata":{"id":"ma08efCr3ryg","executionInfo":{"status":"ok","timestamp":1604205333707,"user_tz":-420,"elapsed":4480,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"dd5da497-5395-412f-a20f-1c2d08847a1d","colab":{"base_uri":"https://localhost:8080/"}},"source":["import numpy as np\n","\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","\n","print(a , b)\n","\n","np.add(a, 1, out = a)\n","print(a)\n","print(b)\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n","[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0nvK5JKyEvRa"},"source":["### CUDA Tensors\n","\n","Tensors can be moved onto any device using the .to method."]},{"cell_type":"code","metadata":{"id":"WxbHBciTEqe1","executionInfo":{"status":"ok","timestamp":1604205418148,"user_tz":-420,"elapsed":1053,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"cdb9f9f2-db5c-4f5f-b819-aac1524336a9","colab":{"base_uri":"https://localhost:8080/"}},"source":["# let us run this cell only if CUDA is available\n","# We will use ``torch.device`` objects to move tensors in and out of GPU\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    z = x + y\n","    print(z)\n","    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"],"execution_count":22,"outputs":[{"output_type":"stream","text":["tensor([1.1247], device='cuda:0')\n","tensor([1.1247], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qNwHJE-UGaHC"},"source":["### How to check GPU with Pytorch"]},{"cell_type":"code","metadata":{"id":"Na6CfIZtGDJM","executionInfo":{"status":"ok","timestamp":1604205450210,"user_tz":-420,"elapsed":951,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"295cdd91-d424-41ca-c9c3-9eb00fbb6aab","colab":{"base_uri":"https://localhost:8080/"}},"source":["torch.cuda.current_device()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"L8VTYf7VGI--","executionInfo":{"status":"ok","timestamp":1604205458288,"user_tz":-420,"elapsed":905,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"ded12939-7c61-4128-9bfd-56f6c6260daa","colab":{"base_uri":"https://localhost:8080/"}},"source":["torch.cuda.device(0)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.cuda.device at 0x7f80c635e0f0>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"V-LbdhNhGK96","executionInfo":{"status":"ok","timestamp":1604205472594,"user_tz":-420,"elapsed":1015,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"b752aaf5-e07b-48f1-bd57-371a71ec1975","colab":{"base_uri":"https://localhost:8080/"}},"source":["torch.cuda.device_count()"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"kCxp5hf8GMcH","executionInfo":{"status":"ok","timestamp":1604205599558,"user_tz":-420,"elapsed":970,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"a90c0e68-24c8-4e3f-a891-4f2f8a7c4816","colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["torch.cuda.get_device_name(0)"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"Hd1rBEyJGOzl","executionInfo":{"status":"ok","timestamp":1604205482407,"user_tz":-420,"elapsed":760,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"0b262456-cf37-4a14-8f03-a1c1335a1778","colab":{"base_uri":"https://localhost:8080/"}},"source":["torch.cuda.is_available()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"FrLBOq2bKIvt"},"source":["## Autograd : Automatic Differentiation"]},{"cell_type":"markdown","metadata":{"id":"srZ6b-0nKQ3c"},"source":["Central to all neural networks in PyTorch is the autograd package. Let’s first briefly visit this, and we will then go to training our first neural network.\n","\n","The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different."]},{"cell_type":"markdown","metadata":{"id":"J_01LZR8Kesg"},"source":["### Tensor\n","\n","\n","``torch.Tensor`` is the central class of the package. If you set its attribute\n","``.requires_grad`` as ``True``, it starts to track all operations on it. When\n","you finish your computation you can call ``.backward()`` and have all the\n","gradients computed automatically. The gradient for this tensor will be\n","accumulated into ``.grad`` attribute.\n","\n","To stop a tensor from tracking history, you can call ``.detach()`` to detach\n","it from the computation history, and to prevent future computation from being\n","tracked.\n","\n","To prevent tracking history (and using memory), you can also wrap the code block\n","in ``with torch.no_grad():``. This can be particularly helpful when evaluating a\n","model because the model may have trainable parameters with\n","``requires_grad=True``, but for which we don't need the gradients.\n","\n","There’s one more class which is very important for autograd\n","implementation - a ``Function``.\n","\n","``Tensor`` and ``Function`` are interconnected and build up an acyclic\n","graph, that encodes a complete history of computation. Each tensor has\n","a ``.grad_fn`` attribute that references a ``Function`` that has created\n","the ``Tensor`` (except for Tensors created by the user - their\n","``grad_fn is None``).\n","\n","If you want to compute the derivatives, you can call ``.backward()`` on\n","a ``Tensor``. If ``Tensor`` is a scalar (i.e. it holds a one element\n","data), you don’t need to specify any arguments to ``backward()``,\n","however if it has more elements, you need to specify a ``gradient``\n","argument that is a tensor of matching shape."]},{"cell_type":"code","metadata":{"id":"4m0v2W91KOEp","executionInfo":{"status":"ok","timestamp":1604206612895,"user_tz":-420,"elapsed":1049,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}}},"source":["import torch"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w9TG_TJKKlI_"},"source":["create a tensor and set requires_grad = True, to track computation with it"]},{"cell_type":"code","metadata":{"id":"tqwlficZKrg1","executionInfo":{"status":"ok","timestamp":1604207146620,"user_tz":-420,"elapsed":1210,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"ca28e015-5d8e-44cb-9b41-62e25b1fe9e3","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = torch.ones(2, 2, requires_grad = True)\n","x"],"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"goxvv2-9MeM2","executionInfo":{"status":"ok","timestamp":1604207146624,"user_tz":-420,"elapsed":908,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}}},"source":["x.grad"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"tH8vBER8KwL7","executionInfo":{"status":"ok","timestamp":1604207146626,"user_tz":-420,"elapsed":651,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"86bb31ef-93b6-4d9c-a050-16a3d138b564","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Do a tensor operation\n","y = x + 2\n","y"],"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[3., 3.],\n","        [3., 3.]], grad_fn=<AddBackward0>)"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"markdown","metadata":{"id":"By6hfsLIK606"},"source":["``y`` was created as aresult of an operation, so it has a grad_fn"]},{"cell_type":"code","metadata":{"id":"GzghPBupK3yt","executionInfo":{"status":"ok","timestamp":1604207148198,"user_tz":-420,"elapsed":620,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"db68717a-659f-4102-f079-4c0a73c7afa3","colab":{"base_uri":"https://localhost:8080/"}},"source":["y.grad_fn"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<AddBackward0 at 0x7f80c62cfcf8>"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"markdown","metadata":{"id":"MbLmSHOhLLbR"},"source":["Do more operations on ``y``"]},{"cell_type":"code","metadata":{"id":"b74d3msFLEJ5","executionInfo":{"status":"ok","timestamp":1604207148725,"user_tz":-420,"elapsed":657,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"02d359d5-ba66-4754-d7cd-f7a57ce3736d","colab":{"base_uri":"https://localhost:8080/"}},"source":["z = y * y * 3\n","out = z.mean()\n","\n","print(z)\n","out"],"execution_count":66,"outputs":[{"output_type":"stream","text":["tensor([[27., 27.],\n","        [27., 27.]], grad_fn=<MulBackward0>)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(27., grad_fn=<MeanBackward0>)"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"markdown","metadata":{"id":"RuAmSXcrL3c7"},"source":["``.requires_grad_( ... )`` changes an existing Tensor’s requires_grad flag in-place. The input flag defaults to False if not given."]},{"cell_type":"code","metadata":{"id":"eme2p9z2LQ1I","executionInfo":{"status":"ok","timestamp":1604207150877,"user_tz":-420,"elapsed":962,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"b8fe56c7-3657-45e0-9fcd-0cc78e1f1cb7","colab":{"base_uri":"https://localhost:8080/"}},"source":["a = torch.randn(2, 2)\n","a = ((a * 3) / (a - 1))\n","print(a.requires_grad)\n","print(a.grad_fn)\n","\n","a.requires_grad_(True)\n","print(a.requires_grad)\n","b = (a * a).sum()\n","print(b.grad_fn)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["False\n","None\n","True\n","<SumBackward0 object at 0x7f80c62ab390>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Sn7imf2O_rx","executionInfo":{"status":"ok","timestamp":1604207775666,"user_tz":-420,"elapsed":722,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"37d74869-615f-4dab-e502-7833d30bc46b","colab":{"base_uri":"https://localhost:8080/"}},"source":["a , b"],"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0.1111, -5.8430],\n","         [-5.7809, -4.3973]], requires_grad=True),\n"," tensor(86.9080, grad_fn=<SumBackward0>))"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"markdown","metadata":{"id":"U2Kio-UCMHe-"},"source":["### Gradient\n","\n","Let's backprop now.\n","Because ``out`` contains a single scalar, ``out.backward()`` is\n","equivalent to ``out.backward(torch.tensor(1.))``\n"]},{"cell_type":"code","metadata":{"id":"gIB3UacmLy48","executionInfo":{"status":"ok","timestamp":1604207153583,"user_tz":-420,"elapsed":1168,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}}},"source":["out.backward()"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4JKxyvkMRyS","executionInfo":{"status":"ok","timestamp":1604207156013,"user_tz":-420,"elapsed":1094,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"bf7d4668-fc4d-41cf-a2ae-5d3245ef8c0a","colab":{"base_uri":"https://localhost:8080/"}},"source":["x.grad"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[4.5000, 4.5000],\n","        [4.5000, 4.5000]])"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"markdown","metadata":{"id":"6hIPqdFlPf2k"},"source":["You should have got a matrix of ``4.5``. Let’s call the ``out``\n","*Tensor* “$o$”.\n","We have that $o = \\frac{1}{4}\\sum_i z_i$,\n","$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n","Therefore,\n","$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence\n","$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HSviA8gMPhgK"},"source":["Mathematically, if you have a vector valued function $\\vec{y}=f(\\vec{x})$,\n","then the gradient of $\\vec{y}$ with respect to $\\vec{x}$\n","is a Jacobian matrix:\n","\n","\\begin{align}J=\\left(\\begin{array}{ccc}\n","   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n","   \\vdots & \\ddots & \\vdots\\\\\n","   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n","   \\end{array}\\right)\\end{align}\n","\n","Generally speaking, ``torch.autograd`` is an engine for computing\n","vector-Jacobian product. That is, given any vector\n","$v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T}$,\n","compute the product $v^{T}\\cdot J$. If $v$ happens to be\n","the gradient of a scalar function $l=g\\left(\\vec{y}\\right)$,\n","that is,\n","$v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$,\n","then by the chain rule, the vector-Jacobian product would be the\n","gradient of $l$ with respect to $\\vec{x}$:\n","\n","\\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n","   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n","   \\vdots & \\ddots & \\vdots\\\\\n","   \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n","   \\end{array}\\right)\\left(\\begin{array}{c}\n","   \\frac{\\partial l}{\\partial y_{1}}\\\\\n","   \\vdots\\\\\n","   \\frac{\\partial l}{\\partial y_{m}}\n","   \\end{array}\\right)=\\left(\\begin{array}{c}\n","   \\frac{\\partial l}{\\partial x_{1}}\\\\\n","   \\vdots\\\\\n","   \\frac{\\partial l}{\\partial x_{n}}\n","   \\end{array}\\right)\\end{align}\n","\n","(Note that $v^{T}\\cdot J$ gives a row vector which can be\n","treated as a column vector by taking $J^{T}\\cdot v$.)\n","\n","This characteristic of vector-Jacobian product makes it very\n","convenient to feed external gradients into a model that has\n","non-scalar output.\n","\n"]},{"cell_type":"code","metadata":{"id":"sdQfvEixPYNH","executionInfo":{"status":"ok","timestamp":1604208027355,"user_tz":-420,"elapsed":1050,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"d6f771ea-6576-447d-935e-250bbbe7bd03","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = torch.randn(3, requires_grad=True)\n","\n","print(x)\n","y = x * 2\n","print(y)\n","while y.data.norm() < 1000:\n","  y = y * 2\n","\n","y"],"execution_count":78,"outputs":[{"output_type":"stream","text":["tensor([-0.2121, -0.0440,  1.0662], requires_grad=True)\n","tensor([-0.4242, -0.0881,  2.1324], grad_fn=<MulBackward0>)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([-217.1754,  -45.0898, 1091.7831], grad_fn=<MulBackward0>)"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"markdown","metadata":{"id":"cbLF4EvDQETc"},"source":["Now in this case ``y`` is no longer scalar. torch.autograd could not compute the full jacobian directly, but if we want the vector Jacobin Product, simple pass the vector to backward as argument"]},{"cell_type":"code","metadata":{"id":"W2sjf3eFPyru","executionInfo":{"status":"ok","timestamp":1604208175981,"user_tz":-420,"elapsed":571,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"5ef4b157-a694-404a-b367-9f5d1bf09d8a","colab":{"base_uri":"https://localhost:8080/"}},"source":["v = torch.tensor([0.1, 1.0, 0.0001], dtype = torch.float)\n","\n","y.backward(v)\n","print(x.grad)"],"execution_count":79,"outputs":[{"output_type":"stream","text":["tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LmVZToLVQ3Tn"},"source":["You can also stop autograd from tracking history on Tensors with ``.requires_grad=True`` either by wrapping the code block in with ``torch.no_grad():``"]},{"cell_type":"code","metadata":{"id":"yU0HsVqKQtTZ","executionInfo":{"status":"ok","timestamp":1604208355809,"user_tz":-420,"elapsed":1036,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"2cd08ce7-2be2-4c83-9725-8b2c21dc35a4","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(x.requires_grad)\n","print((x ** 2).requires_grad)\n","\n","with torch.no_grad():\n","  print((x ** 2).requires_grad)"],"execution_count":88,"outputs":[{"output_type":"stream","text":["True\n","True\n","False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2AWuyL5iRS_z"},"source":["Or by using ``.detach()`` to get a new Tensor with the same content but that does not require gradients:"]},{"cell_type":"code","metadata":{"id":"_dq9rpUuRFc2","executionInfo":{"status":"ok","timestamp":1604208387411,"user_tz":-420,"elapsed":932,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"b76265eb-67b1-43dc-b7b8-4539823d94eb","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(x.requires_grad)\n","y = x.detach()\n","print(y.requires_grad)\n","print(x.eq(y).all())"],"execution_count":89,"outputs":[{"output_type":"stream","text":["True\n","False\n","tensor(True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mEnd8s6-RWEU","executionInfo":{"status":"ok","timestamp":1604208483269,"user_tz":-420,"elapsed":1110,"user":{"displayName":"Yogie Meysa Tama","photoUrl":"","userId":"17632001037686016329"}},"outputId":"ff37beb9-e2d1-4d39-c8a6-d6dc7d83dde3","colab":{"base_uri":"https://localhost:8080/"}},"source":["#  To check tensor equalilty\n","t1 = torch.tensor([1.3, 3])\n","t2 = torch.tensor([1.3, 3])\n","\n","t1.eq(t2), t1.eq(t2).all()"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([True, True]), tensor(True))"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"s7tUviZORkJF"},"source":[""],"execution_count":null,"outputs":[]}]}